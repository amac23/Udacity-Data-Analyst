{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data Project\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "I chose Salt Lake City, UT. I grew up here and know the area pretty well, but was interested in seeing what I would find in the OpenStreetMap data.\n",
    "\n",
    "https://www.openstreetmap.org/relation/198770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map\n",
    "\n",
    "While exploring the data I found the below problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Street names were abbreviated inconsistently, for example Avenue was written 3 different ways on different streets (Ave, Ave., Avenue).\n",
    "\n",
    "\n",
    "* Postcodes were not consistent, for example some postcodes included the state abbreviation before the code (UT 84116).\n",
    "\n",
    "\n",
    "* State names were also inconsistent with their abbreviation, Utah was written 4 different ways (Utah, UT, Ut, ut).\n",
    "\n",
    "\n",
    "* There was an entry for an address in Cincinnati, Ohio. It was the only entry with a city, state, or zipcode outside of the Salt Lake City area. It somehow was errouneoulsy added to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote the below 'update_name' function to programmaticaly fix the first data issues describe above. \n",
    "\n",
    "```\n",
    "def update_name(name, tag_key, tag_type):\n",
    "    if tag_key == 'street' and tag_type == 'addr':\n",
    "        name = name.split(' ')\n",
    "        if name[len(name)-1] in street_mapping.keys():\n",
    "            name[len(name)-1] = street_mapping[name[len(name)-1]]\n",
    "        name =  ' '.join(name)\n",
    "        return name\n",
    "    elif tag_key == 'state' and tag_type == 'addr':\n",
    "        if name in state_mapping.keys():\n",
    "            name = state_mapping[name]\n",
    "        return name\n",
    "    elif tag_key == 'postcode' and tag_type == 'addr':\n",
    "        m = postcode_check.search(name)\n",
    "        name = m.group()\n",
    "        return name\n",
    "    else:\n",
    "        return name\n",
    "```\n",
    "\n",
    "The street names are cleansed using this mapping dictionary:\n",
    "```\n",
    "street_mapping = { \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"E\": \"East\",\n",
    "            \"N\": \"North\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"S\": \"South\",\n",
    "            \"St\": \"Street\",\n",
    "            \"W\": \"West\",\n",
    "            \"W.\": \"West\"}\n",
    "```\n",
    "\n",
    "The states are cleansed using this mapping dictionary:\n",
    "```\n",
    "state_mapping = { \"Utah\": \"UT\",\n",
    "                \"Ut\": \"UT\",\n",
    "                \"ut\": \"UT\"}\n",
    "```\n",
    "\n",
    "The postcodes are cleansed using regex to just return items that are either 5 digit integers or 5 digit integers followed by a '-' and another 4 digit integer:\n",
    "```\n",
    "postcode_check = re.compile('\\d{5}(-\\d{4})?')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data\n",
    "\n",
    "Below are queries that describe the dataset that has been cleansed and loaded into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Size of the file\n",
    "The SLC.osm file is 85 MB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of unique users\n",
    "```\n",
    "SELECT COUNT(DISTINCT user) as total_users \n",
    "FROM (\n",
    "    SELECT user FROM nodes\n",
    "    UNION ALL\n",
    "    SELECT user FROM ways\n",
    ") a;\n",
    "\n",
    "There are 566 unique users\n",
    "```\n",
    "\n",
    "##### Number of Node and Way edits\n",
    "```\n",
    "SELECT COUNT(user) as total_edits\n",
    "FROM (\n",
    "    SELECT user FROM nodes\n",
    "    UNION ALL\n",
    "    SELECT user FROM ways\n",
    ") a;\n",
    "\n",
    "There were 461,566 total edits.\n",
    "```\n",
    "\n",
    "##### Number of Node, Way, and Total edits by each user, with the percent of edits each user made of the total edits (the dataframe below shows the top 5)\n",
    "```\n",
    "SELECT nodes.user\n",
    "    ,node_edits\n",
    "    ,way_edits\n",
    "    ,node_edits + way_edits AS total_edits\n",
    "    ,(node_edits + way_edits) * 1.0 / \n",
    "        (SELECT COUNT(user) FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways)) * 100 \n",
    "     AS percent_of_total\n",
    "FROM (SELECT user, count(*) node_edits FROM nodes GROUP BY user) nodes\n",
    "JOIN (SELECT user, count(*) way_edits FROM ways GROUP BY user) ways\n",
    "ON nodes.user = ways.user\n",
    "ORDER BY total_edits DESC;\n",
    "\n",
    "          node_edits  way_edits  total_edits  percent_of_total\n",
    "user                                                          \n",
    "chadbunn      160129      18515       178644             38.70\n",
    "butlerm        44420       2416        46836             10.15\n",
    "mvexel         35084       4033        39117              8.47\n",
    "wrk3           31582       5153        36735              7.96\n",
    "GaryOSM        18292       3614        21906              4.75\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Percent of total edits made by the top 5 users - 70% of edits came from top 5, 38% from the top user\n",
    "\n",
    "```\n",
    "edits_df.sort_values('percent_of_total',ascending=False)['percent_of_total'].head().plot(kind='bar')\n",
    "```\n",
    "\n",
    "<img src=\"graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 amenities\n",
    "```\n",
    "SELECT value as amenity, COUNT(*) as [count]\n",
    "FROM nodes_tags\n",
    "WHERE key = 'amenity'\n",
    "GROUP BY value\n",
    "ORDER BY [count] DESC\n",
    "LIMIT 10;\n",
    "\n",
    "                  count\n",
    "amenity                \n",
    "restaurant          417\n",
    "place_of_worship    190\n",
    "fast_food           147\n",
    "parking             134\n",
    "bench                99\n",
    "cafe                 75\n",
    "school               67\n",
    "fuel                 53\n",
    "bank                 52\n",
    "toilets              42\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restaurants with more than two locations\n",
    "```\n",
    "SELECT nodes_tags.value as restaurant, COUNT(*) as [count]\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='name'\n",
    "GROUP BY nodes_tags.value\n",
    "HAVING [count] > 2\n",
    "ORDER BY [count] DESC;\n",
    "\n",
    "            count\n",
    "restaurant       \n",
    "Costa Vida      5\n",
    "Pizza Hut       4\n",
    "Cafe Rio        3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One area for imporovement could be fixing the way the 'update_name' function works in regards to street name updating. It only looks at the last word of the street name and updates those, but it doesn't fix any abbreviations of street names that don't fall in the last word of the string. For example if a street is listed as '300 W Temple' it wouldn't update the W to West even though that is in the mapping dictionary. This wouldn't be too difficult to add, it would just require looping through all words in the string. However, it would require making sure that a W is the letter of a Suite or an apartment or something similar. \n",
    "\n",
    "\n",
    "* Looking at the list of restaurants with more than 2 locations, I am thinking there are quite a few things missing. You would expect to see many chain restaurants like Chilli's, IHOP, etc. The list of restaurants is probably far from complete and could use some work to finish out. This might be somewhat manual, but it could be good if it could be automated somehow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
